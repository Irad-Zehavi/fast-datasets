{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patches - enhancing fastai's data classes\n",
    "> Using monkey patching to add functionality to fastai's native classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Sequence, Union\n",
    "from functools import partial\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_datasets.mnist import TinyMNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sublist(self: TfmdLists, indices: Iterable[int]) -> TfmdLists:\n",
    "    \"\"\"a sublist that maintains laziness\"\"\"\n",
    "    sub = self.new_empty()\n",
    "    sub.items = [self.items[i] for i in indices]\n",
    "\n",
    "    all_indices = L(range_of(self))\n",
    "    def subsplit(s):\n",
    "        split_idxs = set(all_indices[s])\n",
    "        return [i for i, j in enumerate(indices) if j in split_idxs]\n",
    "    sub.splits = [subsplit(s) for s in self.splits]\n",
    "    \n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = TfmdLists(list('abcd'), 'f({})'.format, splits=[[0, 1], [2, 3]])\n",
    "sub_l = l.sublist([1, 3])\n",
    "\n",
    "test_eq(sub_l, L('f(b)', 'f(d)'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each split is also intersected with the requested indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(sub_l.train, L('f(b)'))\n",
    "test_eq(sub_l.valid, L('f(d)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sub_dsets(self: Datasets, indices: Iterable[int]):\n",
    "    return Datasets(tls=[t.sublist(indices) for t in self.tls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datasets(list('abcd'), ['f({})'.format, 'g({})'.format], splits=[[0, 1], [2, 3]])\n",
    "sub_ds = ds.sub_dsets([1, 3])\n",
    "\n",
    "test_eq(sub_ds, L(('f(b)', 'g(b)'), ('f(d)', 'g(d)')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each split is also intersected with the requested indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(sub_ds.train, L([('f(b)', 'g(b)')]))\n",
    "test_eq(sub_ds.valid, L([('f(d)', 'g(d)')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def random_sub_dsets(self: Datasets, size, with_replacement=False, less_ok=False) -> Datasets:\n",
    "    if size == 0:\n",
    "        return self.subset([])\n",
    "    if len(self) < size:\n",
    "        assert less_ok\n",
    "        size = len(self)\n",
    "    sampler = random.choices if with_replacement else random.sample\n",
    "    indices = sampler(range(len(self)),  k=size)\n",
    "    return self.sub_dsets(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(ds.random_sub_dsets(2)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(partial(ds.random_sub_dsets, size=6, less_ok=False))\n",
    "test_eq(len(ds.random_sub_dsets(6, less_ok=True)), len(ds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating `TfmdList`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@patch\n",
    "def subset(self: TfmdLists, i):\n",
    "    s = self._new(self._get(self.splits[i]), split_idx=i)\n",
    "    s.splits = [slice(None), []]  # fastai bugfix\n",
    "    return s\n",
    "\n",
    "@patch\n",
    "def __eq__(self: Union[Pipeline, Transform], other: Union[Pipeline, Transform]):\n",
    "    \"\"\"Needed to find shared transforms between TfmdLists\"\"\"\n",
    "    return type(self) == type(other) and self.__dict__ == other.__dict__\n",
    "\n",
    "@patch\n",
    "def __add__(l1: TfmdLists, l2: TfmdLists):\n",
    "    assert l1.split_idx == l2.split_idx\n",
    "\n",
    "    tfms1, tfms2 = copy(list(l1.tfms)), copy(list(l2.tfms))\n",
    "    merged_tfms = []\n",
    "    while tfms1 and tfms2 and tfms1[-1] == tfms2[-1]:\n",
    "        merged_tfms.insert(0, tfms1.pop())\n",
    "        tfms2.pop()\n",
    "    tfms1, tfms2 = Pipeline(tfms1), Pipeline(tfms2)\n",
    "\n",
    "    return TfmdLists(\n",
    "        [[i, item] for i, l in enumerate([l1, l2]) for item in l.items],\n",
    "        tfms=[lambda o: [tfms1, tfms2][o[0]](o[1]), *merged_tfms],\n",
    "        splits=[L(range_of(l1))[s1] + [i+len(l1) for i in L(range_of(l2))[s2]]\n",
    "                for s1, s2 in zip_longest(l1.splits, l2.splits, fillvalue=[])],\n",
    "        do_setup=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = TfmdLists(list('abc'), 'f({})'.format, splits=[[0, 1], [2]])\n",
    "l2 = TfmdLists(list('bcd'), 'g({})'.format, splits=[[0], [1, 2]])\n",
    "\n",
    "test_eq(l1 + l2, L('f(a)', 'f(b)', 'f(c)', 'g(b)', 'g(c)', 'g(d)'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also concatenates each split separtely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq((l1+l2).train, l1.train + l2.train)\n",
    "test_eq((l1+l2).valid, l1.valid + l2.valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shares common transform postfix to allow `show`ing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = TinyMNIST()\n",
    "concat_l = mnist.tls[0]+mnist.tls[0]\n",
    "show_at(concat_l, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating `Datasets`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@patch\n",
    "def __add__(self: Datasets, other: Datasets):\n",
    "    assert len(self.tls) == len(other.tls)\n",
    "    return Datasets(tls=[t1 + t2 for t1, t2 in zip(self.tls, other.tls)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = Datasets(list('abc'), ['f1({})'.format, 'f2({})'.format], splits=[[0, 1], [2]])\n",
    "ds2 = Datasets(list('bcd'), ['g1({})'.format, 'g2({})'.format], splits=[[0], [1, 2]])\n",
    "\n",
    "test_eq(ds1 + ds2, L(('f1(a)', 'f2(a)'), ('f1(b)', 'f2(b)'), ('f1(c)', 'f2(c)'),\n",
    "                     ('g1(b)', 'g2(b)'), ('g1(c)', 'g2(c)'), ('g1(d)', 'g2(d)')))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also concatenates each split separtely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq((ds1+ds2).train, ds1.train + ds2.train)\n",
    "test_eq((ds1+ds2).valid, ds1.valid + ds2.valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting Sub`Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __sub__(self: Datasets, other: Datasets):\n",
    "    assert self.tfms == other.tfms\n",
    "    assert set(other.items).issubset(self.items)\n",
    "    return self.sub_dsets([i for i, o in enumerate(self.items) if o not in set(other.items)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ds-sub_ds, L(('f(a)', 'g(a)'), ('f(c)', 'g(c)')))\n",
    "test_eq((ds-sub_ds).train, L([('f(a)', 'g(a)')]))\n",
    "test_eq((ds-sub_ds).valid, L([('f(c)', 'g(c)')]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch(as_prop=True)\n",
    "def i2t(self: Datasets):\n",
    "    assert self.n_inp == len(self.tls) - 1\n",
    "    return self.tls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datasets(list('abcd'), ['f({})'.format, 'g({})'.format, 'h({})'.format])\n",
    "test_eq(ds.i2t, L('h(a)', 'h(b)', 'h(c)', 'h(d)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch(as_prop=True)\n",
    "def by_target(self: Datasets) -> Dict[int, Datasets]:\n",
    "    if not hasattr(self, '_by_target'):\n",
    "        targets = [int(t) for t in tqdm(self.i2t, desc='Class map: scanning targets')]\n",
    "        class_map = groupby(enumerate(targets), key=1, val=0)\n",
    "        self._by_target = {self.vocab[c]: self.sub_dsets(indices)\n",
    "                           for c, indices in tqdm(class_map.items(), desc='Class map: partitioning')}\n",
    "    return self._by_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datasets(range(10), [noop, [lambda o: ['Even', 'Odd'][o%2], Categorize()]])\n",
    "test_eq(ds.by_target.keys(), ['Even', 'Odd'])\n",
    "test_eq(ds.by_target['Even'], L((i, ds.vocab.o2i['Even']) for i in [0, 2, 4, 6, 8]))\n",
    "test_eq(ds.by_target['Odd'],  L((i, ds.vocab.o2i['Odd'])  for i in [1, 3, 5, 7, 9]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common default parameters for dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ListToTuple(Transform):\n",
    "    \"\"\"Transforms lists to tuples, useful for fixing a bug in pytorch (pin_memory turns inner tuples into lists)\"\"\"\n",
    "    def encodes(self, o:list):\n",
    "        return tuple(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "dl_defaults = {'pin_memory': default_device() != torch.device('cpu'), 'device': default_device(),\n",
    "               'after_item': [ToTensor], 'after_batch': [ListToTuple, IntToFloatTensor]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience methods for creating loaders with `dl_defaults`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _dl_args(kwargs):\n",
    "    args = deepcopy(dl_defaults)\n",
    "    for event in ['after_item', 'after_batch']:\n",
    "        if event in kwargs:\n",
    "            tfms = kwargs[event]\n",
    "            args[event] += tfms if isinstance(tfms, Sequence) else [tfms]\n",
    "    return args\n",
    "\n",
    "\n",
    "@patch\n",
    "def dls(self: Datasets, **kwargs) -> DataLoaders:\n",
    "    \"\"\"Calls `Datasets.dataloaders` with defaults from `dl_defaults`\"\"\"\n",
    "    return self.dataloaders(**_dl_args(kwargs))\n",
    "\n",
    "\n",
    "@patch\n",
    "def dl(self: Datasets, **kwargs) -> DataLoader:\n",
    "    \"\"\"Creates a `DataLoader` (ignoring splits) with defaults from `dl_defaults`\"\"\"\n",
    "    return self._dl_type(self, **_dl_args(kwargs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small enough datasets, we might want to load all of it to memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load(self: Datasets, **kwargs):\n",
    "    return first(self.dl(bs=len(self), **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = TinyMNIST()\n",
    "x, y = mnist.random_sub_dsets(10).load()\n",
    "test_eq(x.shape, [10, 3, 28, 28])\n",
    "test_eq(y.shape, [10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch(as_prop=True)\n",
    "def subsets(self: Datasets) -> TfmdLists:\n",
    "    \"\"\"Lazy list of a `Datasets`'s subsets\"\"\"\n",
    "    return TfmdLists(range(self.n_subsets), self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datasets(list('abcd'), ['f({})'.format, 'g({})'.format], splits=[[0, 2], [1, 3]])\n",
    "test_eq(ds.subsets, L(ds.train, ds.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#2) [('f(a)', 'g(a)'),('f(c)', 'g(c)')]\n",
       "(#2) [('f(b)', 'g(b)'),('f(d)', 'g(d)')]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "@patch()\n",
    "def __repr__(self: Datasets):\n",
    "    return '['+'\\n'.join(repr(s) for s in self.subsets)+']' if self.split_idx is None else coll_repr(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def resplit(self: Datasets,\n",
    "            splits: Union[Callable, List[List[int]]]  # a splitter function or a list of splits\n",
    "            ):\n",
    "    \"\"\"Sets the splits of a `Datasets`\"\"\"\n",
    "    if isinstance(splits, Callable):\n",
    "        splits = splits(self)\n",
    "    for t in self.tls:\n",
    "        t.splits = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datasets(list('abcd'), ['f({})'.format, 'g({})'.format], splits=[[0, 2], [1, 3]])\n",
    "ds.resplit(EndSplitter(.75))\n",
    "\n",
    "test_eq(ds.splits, [[0], [1, 2, 3]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_datasets.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample a random subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mnist.random_sub_dsets(1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = L((c, len(s)) for c, s in mnist.by_target.items()).sorted(0)\n",
    "plt.bar(class_counts.itemgot(0), class_counts.itemgot(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only the even digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evens = mnist.by_target['0'] + mnist.by_target['2'] + mnist.by_target['4'] + mnist.by_target['6'] + mnist.by_target['8']\n",
    "evens.dls().show_batch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop specific classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_than_7 = mnist - mnist.by_target['9'] - mnist.by_target['8'] - mnist.by_target['7']\n",
    "less_than_7.dl().show_batch(max_n=25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the mean sample from a specific class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes_sample = mnist.by_target['3'].random_sub_dsets(20)\n",
    "show_image(threes_sample.load()[0].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
